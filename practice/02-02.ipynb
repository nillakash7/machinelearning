{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Module 2 Part 2: The Machine Learning Process, a Worked Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true,
    "toc-hr-collapsed": false
   },
   "source": [
    "This module consists of 2 parts:\n",
    "\n",
    "- **Part 1** - The Machine Learning Process, a Worked Example (Data Exploration)\n",
    "\n",
    "- **Part 2** - The Machine Learning Process, a Worked Example (Data Modelling)\n",
    "\n",
    "Each part is provided in a separate notebook file. It is recommended that you follow the order of the notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<br>\n",
    "<div class=\"toc\">\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#Module-2-Part-2:-The-Machine-Learning-Process,-a-Worked-Example\" data-toc-modified-id=\"Module-2-Part-2:-The-Machine-Learning-Process,-a-Worked-Example\">Module 2 Part 2: The Machine Learning Process, a Worked Example</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Table-of-Contents\" data-toc-modified-id=\"Table-of-Contents\">Table of Contents</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Data-Sources\" data-toc-modified-id=\"Data-Sources\">Data Sources</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Pre-processing-Pipelines\" data-toc-modified-id=\"Pre-processing-Pipelines\">Pre-processing Pipelines</a></span>\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#Imputers\" data-toc-modified-id=\"Imputers\">Imputers</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Categorical-encoders\" data-toc-modified-id=\"Categorical-encoders\">Categorical encoders</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Feature-scalers\" data-toc-modified-id=\"Feature-scalers\">Feature scalers</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Custom-transformers\" data-toc-modified-id=\"Custom-transformers\">Custom transformers</a></span>\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#Variable-buckets\" data-toc-modified-id=\"Variable-buckets\">Variable buckets</a></span>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><span><a href=\"#Bringing-the-pipeline-together\" data-toc-modified-id=\"Bringing-the-pipeline-together\">Bringing the pipeline together</a></span>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><span><a href=\"#Train-test-Split\" data-toc-modified-id=\"Train-test-Split\">Train-test Split</a></span>\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#Stratified-Sampling\" data-toc-modified-id=\"Stratified-Sampling\">Stratified Sampling</a></span>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><span><a href=\"#Basic-Regressions\" data-toc-modified-id=\"Basic-Regressions\">Basic Regressions</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Advanced-Regressions\" data-toc-modified-id=\"Advanced-Regressions\">Advanced Regressions</a></span>\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#ElasticNet\" data-toc-modified-id=\"ElasticNet\">ElasticNet</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#SGDRegressor\" data-toc-modified-id=\"SGDRegressor\">SGDRegressor</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#DecisionTreeRegressor\" data-toc-modified-id=\"DecisionTreeRegressor\">DecisionTreeRegressor</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#EXERCISE-4:-Building-a-regression-model\" data-toc-modified-id=\"EXERCISE-4:-Building-a-regression-model\">EXERCISE 4: Building a regression model</a></span>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><span><a href=\"#Cross-validation\" data-toc-modified-id=\"Cross-validation\">Cross-validation</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Hyperparameter-Search\" data-toc-modified-id=\"Hyperparameter-Search\">Hyperparameter Search</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Conclusion:-Launch,-Monitor,-Maintain\" data-toc-modified-id=\"Conclusion:-Launch,-Monitor,-Maintain\">Conclusion: Launch, Monitor, Maintain</a></span>\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#Launch\" data-toc-modified-id=\"Launch\">Launch</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Monitor\" data-toc-modified-id=\"Monitor\">Monitor</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Maintain\" data-toc-modified-id=\"Maintain\">Maintain</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Taking-this-further\" data-toc-modified-id=\"Taking-this-further\">Taking this further</a></span>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><span><a href=\"#Exercise-Solutions\" data-toc-modified-id=\"Exercise-Solutions\">Exercise Solutions</a></span>\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#EXERCISE-4\" data-toc-modified-id=\"EXERCISE-4\">EXERCISE 4</a></span>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><span><a href=\"#References\" data-toc-modified-id=\"References\">References</a></span>\n",
    "</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sources\n",
    "\n",
    "You can find the original dataset [here](http://insideairbnb.com/get-the-data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def rmse(a, b):\n",
    "    return np.sqrt(np.mean((a-b)**2))\n",
    "pd.options.display.max_columns = None\n",
    "# to make this notebook's output identical at every run\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Pipelines\n",
    "\n",
    "In Part 1 of the module, we focused on exploring our data. We identified features that require pre-processing before they can be used in a machine learning model. We covered imputation, log transformations, and category binning. In addition to these changes, we will need to transform the data to satisfy the mathematical assumptions of our models. These changes include scaling our numerical data and encoding our categorical data.\n",
    "\n",
    "The `scikit-learn` package has a [pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) that can be used to handle various pre-processing steps. In addition to the pipeline, `pandas` formatted data can be transformed using the [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html). We will use these tools combined with multiple pre-processing techniques to transform the raw data into useable features for machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we'll reload the dataset from the source file and separate the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/toronto_listings_119.csv', index_col='id')\n",
    "# a bit of extra pre-processing\n",
    "# others = [x for x in df['property_type'].value_counts().index if df['property_type'].value_counts()[x] <= 10]\n",
    "# df['property_type'] = df['property_type'].apply(lambda x: 'Other' if x in others else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review the dataset. It has some missing values, lots of categorical variables, and will require some data transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>is_location_exact</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>amenities</th>\n",
       "      <th>price</th>\n",
       "      <th>guests_included</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26999075</th>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>43.658792</td>\n",
       "      <td>-79.416175</td>\n",
       "      <td>f</td>\n",
       "      <td>House</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>{TV,\"Cable TV\",Wifi,\"Air conditioning\",Kitchen...</td>\n",
       "      <td>368.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>flexible</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27552662</th>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>43.775806</td>\n",
       "      <td>-79.413661</td>\n",
       "      <td>f</td>\n",
       "      <td>Condominium</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>{TV,Wifi,\"Air conditioning\",Pool,Kitchen,\"Free...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>flexible</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488787</th>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>43.701005</td>\n",
       "      <td>-79.387345</td>\n",
       "      <td>f</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>{TV,Internet,Wifi,\"Air conditioning\",Kitchen,D...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2</td>\n",
       "      <td>363</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14913091</th>\n",
       "      <td>t</td>\n",
       "      <td>1.0</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>43.669713</td>\n",
       "      <td>-79.385552</td>\n",
       "      <td>t</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>{TV,\"Cable TV\",Wifi,\"Air conditioning\",Kitchen...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>152</td>\n",
       "      <td>99.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22176091</th>\n",
       "      <td>f</td>\n",
       "      <td>2.0</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>43.653078</td>\n",
       "      <td>-79.404302</td>\n",
       "      <td>f</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>{Wifi,Kitchen,Heating,Washer,Dryer,\"Smoke dete...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         host_is_superhost  host_listings_count host_has_profile_pic  \\\n",
       "id                                                                     \n",
       "26999075                 f                  1.0                    t   \n",
       "27552662                 f                  1.0                    t   \n",
       "2488787                  f                  1.0                    t   \n",
       "14913091                 t                  1.0                    t   \n",
       "22176091                 f                  2.0                    t   \n",
       "\n",
       "         host_identity_verified   latitude  longitude is_location_exact  \\\n",
       "id                                                                        \n",
       "26999075                      f  43.658792 -79.416175                 f   \n",
       "27552662                      f  43.775806 -79.413661                 f   \n",
       "2488787                       f  43.701005 -79.387345                 f   \n",
       "14913091                      t  43.669713 -79.385552                 t   \n",
       "22176091                      f  43.653078 -79.404302                 f   \n",
       "\n",
       "         property_type        room_type  accommodates  bathrooms  bedrooms  \\\n",
       "id                                                                           \n",
       "26999075         House  Entire home/apt             4        2.5       2.0   \n",
       "27552662   Condominium  Entire home/apt             3        1.0       1.0   \n",
       "2488787      Apartment  Entire home/apt             2        2.0       1.0   \n",
       "14913091     Apartment     Private room             2        1.0       1.0   \n",
       "22176091     Apartment     Private room             1        1.0       1.0   \n",
       "\n",
       "          beds  bed_type                                          amenities  \\\n",
       "id                                                                            \n",
       "26999075   2.0  Real Bed  {TV,\"Cable TV\",Wifi,\"Air conditioning\",Kitchen...   \n",
       "27552662   1.0  Real Bed  {TV,Wifi,\"Air conditioning\",Pool,Kitchen,\"Free...   \n",
       "2488787    1.0  Real Bed  {TV,Internet,Wifi,\"Air conditioning\",Kitchen,D...   \n",
       "14913091   1.0  Real Bed  {TV,\"Cable TV\",Wifi,\"Air conditioning\",Kitchen...   \n",
       "22176091   1.0  Real Bed  {Wifi,Kitchen,Heating,Washer,Dryer,\"Smoke dete...   \n",
       "\n",
       "          price  guests_included  availability_365  number_of_reviews  \\\n",
       "id                                                                      \n",
       "26999075  368.0                5                 0                  3   \n",
       "27552662  100.0                2                27                  1   \n",
       "2488787    90.0                2               363                  5   \n",
       "14913091   82.0                1                79                152   \n",
       "22176091   54.0                1                87                  1   \n",
       "\n",
       "          review_scores_rating  review_scores_accuracy  \\\n",
       "id                                                       \n",
       "26999075                 100.0                    10.0   \n",
       "27552662                 100.0                    10.0   \n",
       "2488787                  100.0                    10.0   \n",
       "14913091                  99.0                    10.0   \n",
       "22176091                  80.0                    10.0   \n",
       "\n",
       "          review_scores_cleanliness  review_scores_checkin  \\\n",
       "id                                                           \n",
       "26999075                       10.0                   10.0   \n",
       "27552662                       10.0                   10.0   \n",
       "2488787                        10.0                   10.0   \n",
       "14913091                       10.0                   10.0   \n",
       "22176091                        4.0                   10.0   \n",
       "\n",
       "          review_scores_communication  review_scores_location  \\\n",
       "id                                                              \n",
       "26999075                         10.0                    10.0   \n",
       "27552662                         10.0                    10.0   \n",
       "2488787                          10.0                    10.0   \n",
       "14913091                         10.0                    10.0   \n",
       "22176091                         10.0                    10.0   \n",
       "\n",
       "          review_scores_value instant_bookable          cancellation_policy  \\\n",
       "id                                                                            \n",
       "26999075                 10.0                f                     flexible   \n",
       "27552662                 10.0                f                     flexible   \n",
       "2488787                  10.0                f  strict_14_with_grace_period   \n",
       "14913091                 10.0                f                     moderate   \n",
       "22176091                 10.0                f  strict_14_with_grace_period   \n",
       "\n",
       "          reviews_per_month  \n",
       "id                           \n",
       "26999075               0.74  \n",
       "27552662               0.23  \n",
       "2488787                0.09  \n",
       "14913091               5.33  \n",
       "22176091               0.20  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning models generally work best with numerical data only. Therefore, we will need to clean up the data.\n",
    "\n",
    "The first step of setting up our pre-processing pipeline will be identifying the various [`Transformer()`](https://scikit-learn.org/stable/data_transforms.html) classes that we will use. Transformers are Python classes that take `pandas` DataFrames / arrays of values as input, and output transformed arrays that may even have a different shape. \n",
    "\n",
    "The `sklearn` module provides many useful transformers, as well as the ability to create custom transformers. The transformer classes are of the form `Transformer(arguments)` and we will use the `fit(data)`, `transform(data)`, and `fit_transform()` methods to process our data.\n",
    "\n",
    "There are a few important requirements for a good machine learning dataset:\n",
    "\n",
    "1. Features should not have any missing values.<br><br>\n",
    "\n",
    "2. All features must be numerical.<br><br>\n",
    "\n",
    "3. Features should have the same or similar scales (in particular, range and expected value).\n",
    "\n",
    "Many machine learning models assume these requirements are met and will not perform well with data that does not adhere to them.\n",
    "\n",
    "Next, we will cover the main types of transformers necessary for our pipeline. Afterwards, we will show how to link them together to build a pipeline and apply them to our data features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputers\n",
    "\n",
    "The first assumption is that our data has no missing values. During exploration, we discovered this is not the case. There are a number of ways that we can work with missing data. In Part 1 of the module, we simply dropped records where values were missing. This strategy can work in certain circumstances, but we may find that we lose valuable data.\n",
    "\n",
    "Alternatively, we can fill in the missing data according to an appropriate rule. A variety of imputation rules exist. One option is to assign a placeholder value indicating missing data. For example, an \"other\" category. We could also fill in these values according to a measure of central tendency (mean, median, or mode). Or, in special cases, such as time series, we could interpolate values based on the values around them.\n",
    "\n",
    "For **imputation**, we will use the [`SimpleImputer()`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) transformer. This class offers a variety of options we can use for different types of features. For our categorical values, we can assign missing values to an \"other\" category &mdash; e.g. `SimpleImputer(strategy='constant', fill_value='Other')`. For our numerical values, we can use the \"median\" method (`SimpleImputer(strategy='median')`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of all columns which has missing values before the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_is_superhost                 3\n",
       "host_listings_count               3\n",
       "host_has_profile_pic              3\n",
       "host_identity_verified            3\n",
       "bathrooms                        14\n",
       "bedrooms                          7\n",
       "beds                             21\n",
       "review_scores_rating           4034\n",
       "review_scores_accuracy         4044\n",
       "review_scores_cleanliness      4043\n",
       "review_scores_checkin          4048\n",
       "review_scores_communication    4042\n",
       "review_scores_location         4051\n",
       "review_scores_value            4050\n",
       "reviews_per_month              3768\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()[df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check property type feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['House' 'Apartment' 'House' ... 'House' 'Apartment' 'Condominium']\n",
      "[10  2  1 ...  2  4  2]\n"
     ]
    }
   ],
   "source": [
    "print(df[['property_type']].values[:, 0])\n",
    "print(df[['accommodates']].values[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfrom missing values for property_type with 'Other' and accommodates with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['House' 'Apartment' 'House' ... 'House' 'Apartment' 'Condominium']\n",
      "[10  2  1 ...  2  4  2]\n",
      "[10.  2.  1. ...  2.  4.  2.]\n"
     ]
    }
   ],
   "source": [
    "tfmr = SimpleImputer(strategy='constant', fill_value='Other')\n",
    "# we place double brackets as a trick - sklearn expects arrays of the shape (n, 1). \n",
    "# the pandas Series.values method gives the shape (n, ), so we pass a DataFrame instead\n",
    "# by including a list of one column header.\n",
    "print(tfmr.fit_transform(df[['property_type']].values)[:, 0])\n",
    "\n",
    "print(df[['accommodates']].values[:, 0])\n",
    "tfmr = SimpleImputer(strategy='median')\n",
    "print(tfmr.fit_transform(df[['accommodates']].values)[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check how many records are transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(str(df[df['property_type']=='Other'].shape[0]))\n",
    "print(str(df[df['accommodates'] % 1 != 0].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of all columns which has missing values after the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_is_superhost                 3\n",
       "host_listings_count               3\n",
       "host_has_profile_pic              3\n",
       "host_identity_verified            3\n",
       "bathrooms                        14\n",
       "bedrooms                          7\n",
       "beds                             21\n",
       "review_scores_rating           4034\n",
       "review_scores_accuracy         4044\n",
       "review_scores_cleanliness      4043\n",
       "review_scores_checkin          4048\n",
       "review_scores_communication    4042\n",
       "review_scores_location         4051\n",
       "review_scores_value            4050\n",
       "reviews_per_month              3768\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()[df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical encoders\n",
    "\n",
    "Since all of our data has to be numerical, we need a mechanism to transform our categorical data. For our categorical features, we can use **one-hot encoding** to represent the different categories numerically. With this approach, each unique value of a feature is given its own column. Thus, the data will be encoded with a \"1\" in the column which matches the value and a \"0\" in every other column.\n",
    "\n",
    "The use of multiple columns via one-hot encoding ensures that our categorical values are not treated as ordinal data. For example, if instead we used the values \"1\" and \"2\" to represent \"bed\" and \"floor\" in a single column, a model might consider these values as more similar than the values \"1\" and \"4\" representing \"bed\" and \"cot.\" We don't want to introduce additional associations between values through the choice of encoding scheme.\n",
    "\n",
    "We will use the [`OneHotEncoder(sparse=False)`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) transformer. We specify `sparse=False` to avoid outputting a sparse `scipy` matrix. A spare matrix can be extremely useful for handling very large datasets with mostly zero entries. However, for ease of understanding, we will stick to `numpy` arrays for this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['House']\n",
      " ['Apartment']\n",
      " ['House']\n",
      " ...\n",
      " ['House']\n",
      " ['Apartment']\n",
      " ['Condominium']]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(df[['property_type']].values)\n",
    "tfmr = OneHotEncoder(sparse_output=False)\n",
    "print(tfmr.fit_transform(df[['property_type']].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scalers\n",
    "Using different features that have hugely different scales can be problematic for some machine learning models. Therefore, it is good practice to implement a **scaling function** on numerical values. As an example, our `latitude` feature has a very small range and very high mean relative to a feature such as `accommodates`.\n",
    "\n",
    "There are two main scaling methods:\n",
    "\n",
    "1. **Normalization** or *min/max scaling* shifts and rescales data points between the values 0 and 1. This method is more likely to be affected by outliers.<br><br>\n",
    "\n",
    "2. **Standardization** works best with normally distributed data by subtracting the mean value from each data point and dividing by the standard deviation.\n",
    "\n",
    "There is no guaranteed rule for choosing between these methods, but data exploration can help to identify features that may be problematic for either method.\n",
    "\n",
    "We will use the [`MinMaxScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) on all of our numerical (discrete and continuous) features. Our exploration did not reveal many outliers and it is best to use a consistent scaling method. If you would like to experiment, you can replace the `MinMaxScaler()` with the [`StandardScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) and examine the impact on the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  2  1 ...  2  4  2]\n",
      "[0.6        0.06666667 0.         ... 0.06666667 0.2        0.06666667]\n",
      "[43.64616766 43.64105127 43.66724069 ... 43.67788972 43.66907246\n",
      " 43.63804609]\n",
      "[-0.69774523 -0.80533284 -0.25462118 ... -0.03069313 -0.21610266\n",
      " -0.8685259 ]\n"
     ]
    }
   ],
   "source": [
    "print(df[['accommodates']].values[:, 0])\n",
    "tfmr = MinMaxScaler()\n",
    "print(tfmr.fit_transform(df[['accommodates']].values)[:, 0])\n",
    "\n",
    "print(df[['latitude']].values[:, 0])\n",
    "tfmr = StandardScaler()\n",
    "print(tfmr.fit_transform(df[['latitude']].values)[:, 0])\n",
    "\n",
    "# NOTE: If you get a DataConversionWarning you can safely ignore it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom transformers\n",
    "There are a great variety of transformers available in the `sklearn` package. However, if you can't find a transformer that suit your needs, it is straightforward to create your own! Any function can be easily wrapped in a tranformer class using the [`FunctionTransformer()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html).\n",
    "\n",
    "Here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  2  1 ...  2  4  2]\n",
      "[11  3  2 ...  3  5  3]\n"
     ]
    }
   ],
   "source": [
    "def plusone(x):\n",
    "    return x + 1\n",
    "\n",
    "# print the original values\n",
    "print(df[['accommodates']].values[:, 0])\n",
    "\n",
    "# apply the transformation\n",
    "tfmr = FunctionTransformer(func=plusone, validate=False)\n",
    "\n",
    "# print the values plus one\n",
    "print(tfmr.fit_transform(df[['accommodates']].values)[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable buckets\n",
    "\n",
    "We should sort our features according to the different transformations each feature will need. In the code below, there are four different buckets.\n",
    "\n",
    "1. The categorical variables will need to be imputed and encoded.<br><br>\n",
    "\n",
    "2. The discrete variables will be imputed and scaled.<br><br>\n",
    "\n",
    "3. The continuous variables will also be imputed and scaled.<br><br>\n",
    "\n",
    "4. The dependent variable `price` will be imputed.\n",
    "\n",
    "**NOTE:** The dependent variable typically does not need to be scaled. And, for our purposes, avoiding scaling will make it easier to understand our models' performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from Part 1, our data types\n",
    "categorical_vars = ['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified',\n",
    "            'is_location_exact', 'property_type', 'room_type', 'bed_type', \n",
    "            'instant_bookable', 'cancellation_policy']\n",
    "\n",
    "discrete_vars = ['host_listings_count', 'accommodates', 'bathrooms', 'bedrooms', 'beds',\n",
    "                 'guests_included', 'availability_365']\n",
    "\n",
    "continuous_vars = ['latitude', 'longitude']\n",
    "\n",
    "dep_var = ['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow for `ColumnTransformer` pipelines generally includes these steps:\n",
    "\n",
    "1. **Transformers**: In this case, the ones we have already discussed.<br><br>\n",
    "\n",
    "2. **Pipelines**: These link together sequential transformers, making a chain of transformers that will each take in an input array or matrix and pass on the transformed output. The [`Pipeline()`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) function takes as input a list of `(name, transformer)` tuples.<br><br>\n",
    "\n",
    "3. **ColumnTransformer**: This function will apply any number of pipelines to designated columns of a 2-dimensional data structure, making it suitable for working with `pandas` DataFrames. By indicating which pipelines apply to which columns, we can build a concise workflow that works with a variety of features that require different transformations. The [`ColumnTransformer()`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) pipeline takes as input a list of `(name, pipeline, column_headers)` tuples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing the pipeline together\n",
    "\n",
    "Here are the transformation pipelines for the categorical and independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical - impute, one hot encode\n",
    "cat_si_step = ('si', SimpleImputer(strategy='constant', fill_value='Other'))\n",
    "cat_ohe_step = ('ohe', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "cat_steps = [cat_si_step, cat_ohe_step]\n",
    "cat_pipe = Pipeline(cat_steps)\n",
    "cat_transformers = [('cat', cat_pipe, categorical_vars)]\n",
    "\n",
    "# Numerical - impute, scale\n",
    "num_si_step = ('si', SimpleImputer(strategy='median'))\n",
    "num_scl_step = ('scl', MinMaxScaler())\n",
    "num_steps = [num_si_step, num_scl_step]\n",
    "num_pipe = Pipeline(num_steps)\n",
    "num_transformers = [('num', num_pipe, discrete_vars + continuous_vars)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use our pipelines to transform our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers=cat_transformers + num_transformers)\n",
    "ct.fit(df[categorical_vars + discrete_vars + continuous_vars])\n",
    "X = ct.transform(df[categorical_vars + discrete_vars + continuous_vars])\n",
    "# We know from our exploration that the dependent variable 'price' does not have any missing values. \n",
    "# It is also generally not necessary to apply transformations to normalize or scale\n",
    "# the dependent variable.\n",
    "y = df[['price']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating machine learning models, it is good practice to split your data into subsets: training data and testing data (we can also include a validation subset). This should be done randomly to avoid introducing bias. We fit the model on the training data and test its prediction strength on the testing data using our performance metric. This can help us identify two potential problems: overfitting or underfitting the model.\n",
    "\n",
    "1. **Overfitting** is when a model has been too finely tuned towards the training dataset. This issue can often arise in cases where there are relatively few datapoints compared to the number of features. The model may be finding many relationships that are not actually generalizable beyond the training dataset, giving it poor performance on a test dataset that it has not seen before.<br><br>\n",
    "\n",
    "2. **Underfitting** occurs when a model does not fit the training data well and is unable to find trends. Underfitting is more likely to occur in the case of a dataset that is too simple (few relevant independent variables) or when there is a mismatch between the data and the model chosen (e.g. a linear model for a non-linear relationship).\n",
    "\n",
    "Sklearn has the useful [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function for this purpose. We will split our independent $X$ values and dependent $y$ values each into a train set and a test set. A $\\text{20%}$ split is a typical parameter to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15717, 68) (3930, 68) (15717, 1) (3930, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Sampling\n",
    "\n",
    "Random sampling is an effective way to avoid **sampling bias**, which occurs when certain groups in a dataset are over- or under-sampled. However, in small datasets random sampling can miss key structure in the data that is important to our research question, especially if we are interested in the tail ends of our dependent variable (e.g. the highest price AirBnB offerings). We can aim to preserve the overall distribution of data in our train and test datasets by using **stratified sampling**. \n",
    "\n",
    "For stratified sampling we segment our dataset into equally spaced **strata** and maintain the proportion of data in each stratum for our subsets.\n",
    "\n",
    "In Part 1 of the module, we saw that the `latitude` feature follows a somewhat bimodal distribution. Intuitively, we should also expect latitude to be an important feature &mdash; e.g. the farther south we are in Toronto, the closer to downtown. To ensure that this feature is sampled in a way that maintains its proportions, let's try stratified sampling.\n",
    "\n",
    "Sklearn offers the [`StratifiedShuffleSplit()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html) class to make stratified sampling easy. We will use the `split()` method and provide our dataset and the chosen feature as arguments. The method will maintain even proportions across the chosen feature in the train and test datasets. We will first have to make a new column to create strata for our continuous latitude variable. In this case, we can simply multiply by 10 and take the ceiling (`[np.ceil()`](https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.ceil.html) to get five equally spaced and discrete strata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat_cat\n",
      "437.0    3017\n",
      "438.0     838\n",
      "439.0      57\n",
      "436.0      17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['lat_cat'] = np.ceil(df['latitude']*10)\n",
    "print(df['lat_cat'].sample(frac=.2, random_state=0).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the `split()` method. This will provide us with indices that we can use to select from our $X$ and $y$ data, even though we got the indices from our original `df`. Our output should show dimensions of four arrays. The first two will have the same number of columns (all of our independent variables) and the second two will have one column (our dependent variable). They will be split in a ratio of 4:1 (or 0.8:0.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15717, 68) (3930, 68) (15717, 1) (3930, 1)\n"
     ]
    }
   ],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "\n",
    "# note that we pass the dataframe as arguments to the .split() method \n",
    "# rather than the numpy matrix X. This is done for easy comprehension\n",
    "# as the numpy matrix no longer has labelled columns. You can compare the\n",
    "# shapes of X and df to ensure we are getting the right rows.\n",
    "for train_index, test_index in split.split(df, df['lat_cat'].fillna(df['lat_cat'].median())):\n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "        \n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Regressions\n",
    "\n",
    "We are now ready to build some models! At this stage in the course, we will not focus on the details of each model. Different types of regression models and their strengths and weaknesses will be covered in a later module. However, it is good practice to try a few different models for comparison. Below we will implement a simple linear regression using `sklearn`'s [`LinearRegression()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) model. The widely used ordinary least squares (OLS) regression is a tried and true method for picking up relationships in data and using these relationships to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy_X&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">positive&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write a simple function to print out our results, including our accuracy metric ($\\text{RMSE}$), and a sample of 5 predicted and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 245.27292802777873\n",
      "Predicted 1-5: [ 50.27816008  75.82746176 143.86736309  55.75755496  64.58525762]\n",
      "Actual 1-5: [ 45.  38.  76.  69. 100.]\n"
     ]
    }
   ],
   "source": [
    "def display_results(model, X, y):\n",
    "    print(\"RMSE:\", rmse(model.predict(X), y))\n",
    "    print(\"Predicted 1-5:\", model.predict(X_test[0:5]))\n",
    "    print(\"Actual 1-5:\", y_test[0:5, 0])\n",
    "    \n",
    "display_results(reg, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Regressions\n",
    "\n",
    "Next, we will implement the more advanced ElasticNet regression model ([`ElasticNet()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet)), as well as the stochastic gradient descent regressor ([`SGDRegressor()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor)) and the random forest regressor ([`RandomForestRegressor()`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)). Each of these methods takes a different approach towards regression. Check out the [sklearn generalized linear models](https://scikit-learn.org/stable/modules/linear_model.html) documentation for an overview of these models and many others. You can also try implementing one of the other models described on that page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet\n",
    "\n",
    "The ElasticNet model implements methods to help with assumptions made in OLS regression. You do not need to worry about the details for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 229.0536008162524\n",
      "Predicted 1-5: [ 97.60287359 107.13705813 161.25775042 111.17237008  95.65962275]\n",
      "Actual 1-5: [ 45.  38.  76.  69. 100.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "enr = ElasticNet()\n",
    "enr.fit(X_train, np.ravel(y_train))\n",
    "display_results(enr, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ElasticNet performs better than the OLS regression, with a lower $\\text{RMSE}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDRegressor\n",
    "\n",
    "Next, we will try the SGDRegressor, an old optimization method that has more recently become a standard component  of artificial neural networks (along with [backpropogation](https://en.wikipedia.org/wiki/Backpropagation)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 242.03274785525838\n",
      "Predicted 1-5: [ 61.10641599  78.43761646 136.30303542  65.25874821  55.8051915 ]\n",
      "Actual 1-5: [ 45.  38.  76.  69. 100.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "clf = SGDRegressor(tol=1e-3)\n",
    "clf.fit(X_train, np.ravel(y_train))\n",
    "display_results(clf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SGDRegressor performs only slightly better than OLS regression based on its $\\text{RMSE}$ value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeRegressor\n",
    "\n",
    "Decision tree models create \"branches\" at different feature values &mdash; e.g. a private home will lead to a prediction of a higher price. Decision trees and related models are valuable for ease of interpretation &mdash; the `sklearn` class makes it easy to determine which features were most important in the training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 309.1109588390924\n",
      "Predicted 1-5: [ 49.  84. 102.  76.  31.]\n",
      "Actual 1-5: [ 45.  38.  76.  69. 100.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(X_train, np.ravel(y_train))\n",
    "display_results(dtr, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some notable underfitting in the DecisionTreeRegressor based on its higher $\\text{RMSE}$ value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 4: Building a regression model\n",
    "\n",
    "Check out the list of regression models available in [`sklearn`](https://scikit-learn.org/stable/modules/linear_model.html). Try implementing one not listed above, and run it multiple times with some different parameters.\n",
    "\n",
    "If you are interested in understanding some of the improvements made in the ElasticNet model, try the [`Ridge`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) or [`Lasso`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) models.\n",
    "\n",
    "If you would like to improve on the DecisionTreeRegressor you could try the [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html), an ensemble model that fits multiple decision tree regressors over subsets of the data. This is most effective when you have overfitting in your decision tree, but can still improve on $\\text{RMSE}$ in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation\n",
    "\n",
    "Splitting our data into a train set and a test set is a good start to avoiding overfitting. However, for a more comprehensive assessment of model performance we should cross-validate our models.\n",
    "\n",
    "**K-fold cross validation** is a method where we randomly split our data into $k$ subsets called **folds**. We then train our model $k$ times, each time picking one fold as our validation or test set and training on the remaining subsets. This method greatly reduces sampling bias and gives us an estimate not just of average model performance, but also the standard deviation of model performance. This extra information allows us to assess both the precision and accuracy of our model.\n",
    "\n",
    "We can use `sklearn`'s `cross_val_score()` function for easy cross-validation. Sklearn provides a number of different options for performance metrics. We will select `'neg_mean_squared_error'` and keep in mind that we will have to take the negative and square root of the result to get $\\text{RMSE}$. Remember that the lower the $\\text{RMSE}$ is, the better our model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([129.36841654, 325.20647905, 251.16609114, 215.60607491,\n",
       "       128.32872966])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "enr = ElasticNet()\n",
    "scores = cross_val_score(enr, X, np.ravel(y), cv=5, scoring='neg_mean_squared_error')\n",
    "np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write a simple function to print out our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [129.36841654 325.20647905 251.16609114 215.60607491 128.32872966]\n",
      "Mean: 209.9351582610659\n",
      "Standard deviation: 75.06028987182748\n"
     ]
    }
   ],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", np.sqrt(-scores))\n",
    "    print(\"Mean:\", np.sqrt(-scores).mean())\n",
    "    print(\"Standard deviation:\", np.sqrt(-scores).std())\n",
    "\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [117.55962238 316.84331455 239.54004707 204.10284085 116.73609084]\n",
      "Mean: 198.95638314061605\n",
      "Standard deviation: 76.10053551829925\n"
     ]
    }
   ],
   "source": [
    "clf = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "scores = cross_val_score(clf, X, np.ravel(y), cv=5, scoring='neg_mean_squared_error')\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [265.33405034 343.58032829 387.38323588 229.38951092 272.5925889 ]\n",
      "Mean: 299.65594286585684\n",
      "Standard deviation: 57.398986867388814\n"
     ]
    }
   ],
   "source": [
    "rfr = DecisionTreeRegressor()\n",
    "scores = cross_val_score(dtr, X, np.ravel(y), cv=5, scoring='neg_mean_squared_error')\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add cross-validation for your model from exercise 4 here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our ElasticNet model still looks effective, we actually find that the SGD regressor has, on average, a lower $\\text{RMSE}$. Cross-validation can give you much more confidence in your calculation of performance metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Search\n",
    "\n",
    "Once we have chosen a model type, it is important to tune its **hyperparameters**. The hyperparameters are the parameters that are decided before beginning the training process. We have already seen some hyperparameters as arguments above (e.g. for SGDRegressor). We will discard the assumption that these default hyperparameters are the best possible options, and we will instead test different parameters to determine which works best.\n",
    "\n",
    "For our hyperparameter search we can use grid search or randomized search.\n",
    "\n",
    "* **Grid search** tries every possible combination from lists of different parameters and determines which combination is most effective.<br><br>\n",
    "\n",
    "* **Randomized search** will select random combinations of hyperparameters following defined rules or boundaries. This method is effective for very large search spaces, where trying out every combination is not computationally practical.\n",
    "\n",
    "For this module, we will use grid search. Sklearn's [`GridSearchCV()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) class implements this method alongside cross-validation for a convenient hyperparameter search. See below for implementing GridSearchCV with the SGDRegressor. Randomized search is also available with [`RandomizedSearchCV()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html). Finally, some models (e.g. ElasticNet) have more efficient hyperparameter search methods based on their mathematical characteristics (see [`ElasticNetCV`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html#sklearn.linear_model.ElasticNetCV)).\n",
    "\n",
    "The output printed from this code simply describes the settings chosen for the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 21\u001b[0m\n\u001b[0;32m     16\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mclf, \n\u001b[0;32m     17\u001b[0m                            param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m     18\u001b[0m                            scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     19\u001b[0m                            cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# last, we fit our data. This will take a while...\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\frahman2\\AppData\\Local\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\frahman2\\AppData\\Local\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1046\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1047\u001b[0m     )\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\frahman2\\AppData\\Local\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1605\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\frahman2\\AppData\\Local\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    993\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    994\u001b[0m         )\n\u001b[0;32m    995\u001b[0m     )\n\u001b[1;32m--> 997\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1017\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1019\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1020\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\frahman2\\AppData\\Local\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     75\u001b[0m     (\n\u001b[0;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\frahman2\\AppData\\Local\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1984\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1985\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1988\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1989\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1992\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1993\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\frahman2\\AppData\\Local\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1914\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\frahman2\\AppData\\Local\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig), warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    146\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilters \u001b[38;5;241m=\u001b[39m warning_filters\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\frahman2\\AppData\\Local\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:859\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    857\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 859\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    863\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\frahman2\\AppData\\Local\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\frahman2\\AppData\\Local\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1618\u001b[0m, in \u001b[0;36mBaseSGDRegressor.fit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m   1592\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit linear model with Stochastic Gradient Descent.\u001b[39;00m\n\u001b[0;32m   1593\u001b[0m \n\u001b[0;32m   1594\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1614\u001b[0m \u001b[38;5;124;03m    Fitted `SGDRegressor` estimator.\u001b[39;00m\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1616\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_more_validate_params()\n\u001b[1;32m-> 1618\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoef_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintercept_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1627\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\frahman2\\AppData\\Local\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561\u001b[0m, in \u001b[0;36mBaseSGDRegressor._fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# Clear iteration count for multiple call to fit.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m-> 1561\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1563\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1572\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m   1577\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter\n\u001b[0;32m   1578\u001b[0m ):\n\u001b[0;32m   1579\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1580\u001b[0m         (\n\u001b[0;32m   1581\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximum number of iteration reached before \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1585\u001b[0m         ConvergenceWarning,\n\u001b[0;32m   1586\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\frahman2\\AppData\\Local\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1489\u001b[0m, in \u001b[0;36mBaseSGDRegressor._partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m   1486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_average_coef \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_features, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1487\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_average_intercept \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1489\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_regressor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\frahman2\\AppData\\Local\\anaconda3\\envs\\machinelearning\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1702\u001b[0m, in \u001b[0;36mBaseSGDRegressor._fit_regressor\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, sample_weight, max_iter)\u001b[0m\n\u001b[0;32m   1699\u001b[0m     average_intercept \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Not used\u001b[39;00m\n\u001b[0;32m   1701\u001b[0m _plain_sgd \u001b[38;5;241m=\u001b[39m _get_plain_sgd_function(input_dtype\u001b[38;5;241m=\u001b[39mcoef\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m-> 1702\u001b[0m coef, intercept, average_coef, average_intercept, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_plain_sgd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1703\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1705\u001b[0m \u001b[43m    \u001b[49m\u001b[43maverage_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43maverage_intercept\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpenalty_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_l1_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_score_cb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1716\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter_no_change\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1719\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1720\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1721\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1723\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1724\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meta0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1727\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpower_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1728\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1731\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m*\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# we create a dictionary of lists, each key is a parameter name\n",
    "# and the list is the possible values it can take\n",
    "# we have reduced the grid options to allow faster parameter searching\n",
    "# for a larger search you can include 'l1' and 'elasticnet' penalties\n",
    "# and 'constant' and 'optimal' learning_rates\n",
    "param_grid = {\n",
    "    'alpha': 10.0 ** -np.arange(4, 7),\n",
    "    'loss': ['squared_error', 'huber', 'epsilon_insensitive'],\n",
    "    'penalty': ['l2'],\n",
    "    'learning_rate': ['invscaling'],\n",
    "}\n",
    "# we can bump up the max_iterations parameter, otherwise some of our models will fail to converge\n",
    "clf = SGDRegressor(max_iter=10000, tol=1e-3)\n",
    "# we pass the model, our parameter grid, and cross-validation parameters to the class\n",
    "grid_search = GridSearchCV(estimator=clf, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           cv=5)\n",
    "# last, we fit our data. This will take a while...\n",
    "grid_search.fit(X=X, y=np.ravel(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at our `grid_search`'s `best_params_` and `best_estimator_` attributes to see which combination of hyperparameters was ultimately the most effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-06, 'learning_rate': 'invscaling', 'loss': 'squared_error', 'penalty': 'l2'}\n",
      "\n",
      " SGDRegressor(alpha=1e-06, max_iter=10000)\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(\"\\n\",grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print out the results of all of the models tested. Let's add a rule to filter down to only those which performed better than the default version we found originally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = grid_search.cv_results_\n",
    "for mean_score, params in zip(cv_scores['mean_test_score'], cv_scores['params']):\n",
    "    if np.sqrt(-mean_score) < 171.9:\n",
    "        print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's grab our best model and do some performance testing. First, on our original test set, and then with our cross-validation methodology. Here the output will show the accuracy ($\\text{RMSE}$) of the best model, as well as a sample of five predicted and actual scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 272.91712159664814\n",
      "Predicted 1-5: [ 60.77121061  74.32978719 137.06947256  63.00767976  56.41142512]\n",
      "Actual 1-5: [ 45.  38.  76.  69. 100.]\n"
     ]
    }
   ],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "display_results(final_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [117.14723766 316.43341753 239.22566595 204.3771353  118.0118789 ]\n",
      "Mean: 199.03906706819285\n",
      "Standard deviation: 75.75825785844124\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(final_model, X, np.ravel(y), cv=5, scoring='neg_mean_squared_error')\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: Launch, Monitor, Maintain\n",
    "\n",
    "Getting a model up an running is only the beginning of successful machine learning. For your model to be useful, it will likely need to be launched; set up for automated data ingestion and reporting; monitored for performance drops; and maintained or improved over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch\n",
    "\n",
    "First, always save any models you work on. Sklearn's [`joblib`](https://scikit-learn.org/stable/modules/model_persistence.html) provides methods to save models as a `.pkl` file (a standard python format for serializing data objects). Simply dump your model into a file, and load it back up when you need it or want to share it with a colleague."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(my_model, \"my_model.pkl\")\n",
    "my_model_loaded = joblib.load(\"my_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is often new data available, writing code to automate the process of scraping new datasets and using them to further train your model will help it improve over time. Otherwise, performance can degrade over time as real word data and its underlying trends evolve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor\n",
    "\n",
    "If your model will be changing over time, it is essential to plan for regular testing. A wide range of scenarios can break your model, and you want to prepare for as many of them as possible. The introduction of new data features or removal of old features, changing data formats, and changes to the packages being used are just some examples of what could go wrong. Be sure to study up on version control and unit tests before deploying any machine learning model.\n",
    "\n",
    "You will also want to monitor for performance. Having automated systems in place to calculate and report on performance metrics will allow for faster resolution of issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maintain\n",
    "\n",
    "Ultimately, you will need some level of human intervention to not only keep your model running smoothly, but also to help it improve over time. When tests fail or performance drops, there will be many possible causes, so it is important to know who is responsible for checking in on any problems and fixing them as they arise. Ideally, you can automate the learning process. If you do, be sure to save versions of your model at regular intervals so you can compare between different versions and roll back to an older version if necessary. Upload your code to a public or private repository like GitHub to easily track changes that you or others make over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Taking this further\n",
    "\n",
    "If you're interested in exploring ways to improve the models used here, don't hesitate to play around! You can download additional data from the AirBnB website linked below. Try choosing a different city or a different time period.\n",
    "\n",
    "You can also choose to include more features from the dataset. The `amenities` feature in particular contains a rich store of information, but in an inconvenient format. It would be excellent practice to take this feature, create a pre-processing pipeline that will turn it into usable numerical values, and include it in the models explored above. You will have to employ some Python string methods to parse the values contained in the feature, or you can use a text-based encoding method such as the `FeatureHasher()` or `CountVectorizer()`.\n",
    "\n",
    "A more advanced model would consider how the AirBnB landscape changes over time. There might be trends picked up in a year's worth of data that are not seen within any one month. There may also be other interesting features that aren't found directly in the data. This incomplete [kaggle kernel](https://www.kaggle.com/rudymizrahi/how-i-ranked-5th-160-in-deloitte-s-ml-competition) suggests calculating the distance of each location from the downtown core."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End of Module**\n",
    "\n",
    "This notebook makes up one part of this module. Now that you have completed this part, please proceed to the next notebook in this module.\n",
    "\n",
    "If you have any questions, please reach out to your peers using the discussion boards. If you and your peers are unable to come to a suitable conclusion, do not hesitate to reach out to your instructor on the designated discussion board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(n_estimators=10)\n",
    "rfr.fit(X_train, np.ravel(y_train))\n",
    "print(rmse(rfr.predict(X), y))\n",
    "print()\n",
    "print(rfr.predict(X_test[0:5]))\n",
    "print(y_test[0:5, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "rfr = RandomForestRegressor(n_estimators=10)\n",
    "scores = cross_val_score(rfr, X, np.ravel(y), cv=5, scoring='neg_mean_squared_error')\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# References\n",
    "\n",
    "AirBnB. (2019). Detailed Listings data for Toronto, January 2019. Retrieved from http://insideairbnb.com/get-the-data.html."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "496px",
    "width": "386px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "374px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
